{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pprint\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.utils import generic_utils\n",
    "import configparser\n",
    "import math\n",
    "from data_generator import data_generators\n",
    "from models import vgg as nn\n",
    "from models import losses as model_losses\n",
    "from models import roi_helpers\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load configuration file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('training_config.conf')\n",
    "model_params = {}\n",
    "    \n",
    "verbose = eval(config['model_params']['verbose'])\n",
    "\n",
    "# setting for data augmentation\n",
    "use_horizontal_flips = eval(config['model_params']['use_horizontal_flips'])\n",
    "use_vertical_flips = eval(config['model_params']['use_vertical_flips'])\n",
    "rot_90 = eval(config['model_params']['rot_90'])\n",
    "\n",
    "# anchor box scales\n",
    "# Note that if im_size is smaller, anchor_box_scales should be scaled\n",
    "# Original anchor_box_scales in the paper is [128, 256, 512]\n",
    "model_params['anchor_box_scales'] = eval(config['model_params']['anchor_box_scales'])\n",
    "\n",
    "# anchor box ratios\n",
    "model_params['anchor_box_ratios'] = [[1, 1], [1./math.sqrt(2), 2./math.sqrt(2)], [2./math.sqrt(2), 1./math.sqrt(2)]]\n",
    "\n",
    "# size to resize the smallest side of the image\n",
    "# Original setting in paper is 600. Set to 416 in here to save training time\n",
    "model_params['im_size'] = eval(config['model_params']['im_size'])\n",
    "\n",
    "# image channel-wise mean to subtract\n",
    "model_params['img_channel_mean'] = eval(config['model_params']['img_channel_mean'])\n",
    "model_params['img_scaling_factor'] = eval(config['model_params']['img_scaling_factor'])\n",
    "\n",
    "# number of ROIs to process at once\n",
    "num_rois = eval(config['model_params']['num_rois'])\n",
    "\n",
    "# stride at the RPN (this depends on the network configuration)\n",
    "model_params['rpn_stride'] = eval(config['model_params']['rpn_stride'])\n",
    "\n",
    "balanced_classes = False\n",
    "\n",
    "# scaling the stdev\n",
    "model_params['std_scaling'] = eval(config['model_params']['std_scaling'])\n",
    "model_params['classifier_regr_std'] = eval(config['model_params']['classifier_regr_std'])\n",
    "\n",
    "# overlaps for RPN\n",
    "model_params['rpn_min_overlap'] = eval(config['model_params']['rpn_min_overlap'])\n",
    "model_params['rpn_max_overlap'] = eval(config['model_params']['rpn_max_overlap'])\n",
    "\n",
    "# overlaps for classifier ROIs\n",
    "model_params['classifier_min_overlap'] = eval(config['model_params']['classifier_min_overlap'])\n",
    "model_params['classifier_max_overlap'] = eval(config['model_params']['classifier_max_overlap'])\n",
    "\n",
    "# placeholder for the class mapping, automatically generated by the parser\n",
    "class_mapping = None\n",
    "\n",
    "model_path = eval(config['outputs']['model_path'])\n",
    "model_path_regex = re.match(\"^(.+)(\\.hdf5)$\", model_path)\n",
    "if model_path_regex.group(2) != '.hdf5':\n",
    "\tprint('Output weights must have .hdf5 filetype')\n",
    "\texit(1)\n",
    "\n",
    "# Input path for weights. If not specified, will try to load default weights provided by keras.\n",
    "input_weight_path = eval(config['inputs']['input_weight_path'])\n",
    "\n",
    "# Location to store all the metadata related to the training (to be used when testing).\n",
    "class_mapping_filename = eval(config['outputs']['class_mapping'])\n",
    "\n",
    "# get data option out of txt or xml\n",
    "data_options = eval(config['inputs']['data_options'])\n",
    "\n",
    "num_epochs = eval(config['model_params']['num_epochs'])\n",
    "\n",
    "record_path = 'record.csv' # Record data (used to save the losses, classification accuracy and mean average precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if weight path was passed via command line\n",
    "if input_weight_path:\n",
    "\tbase_net_weights = input_weight_path\n",
    "else:\n",
    "\t# set the path to weights based on backend and model\n",
    "\tbase_net_weights = nn.get_weight_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_options == 'xml':\n",
    "\t# training data path\n",
    "\tdata_path = eval(config['inputs']['data_path'])\n",
    "\tfrom data_generator.pascal_voc_parser import get_data\n",
    "elif data_options == 'txt':\n",
    "\ttrain_data_path = eval(config['inputs']['train_annotation'])\n",
    "\tval_data_path = eval(config['inputs']['val_annotation'])\n",
    "\ttest_data_path = eval(config['inputs']['test_annotation'])\n",
    "\tfrom data_generator.simple_parser import get_data\n",
    "else:\n",
    "\traise ValueError(\"data_options must be one of 'xml' or 'txt'\")\n",
    "\n",
    "all_imgs1, classes_count, class_mapping = get_data(test_data_path)\n",
    "all_imgs2, classes_count, class_mapping = get_data(val_data_path)\n",
    "all_imgs, classes_count, class_mapping = get_data(train_data_path)\n",
    "all_imgs = all_imgs + all_imgs1 + all_imgs2\n",
    "\n",
    "if 'bg' not in classes_count:\n",
    "\tclasses_count['bg'] = 0\n",
    "\tclass_mapping['bg'] = len(class_mapping)\n",
    "\n",
    "# inv_map for converting class index back to class\n",
    "inv_map = {v: k for k, v in class_mapping.items()}\n",
    "\n",
    "print('Training images per class:')\n",
    "pprint.pprint(classes_count)\n",
    "print(f'Num classes (including bg) = {len(classes_count)}')\n",
    "\n",
    "# save class mapping\n",
    "with open(class_mapping_filename, 'wb') as f:\n",
    "\tpickle.dump(class_mapping, f)\n",
    "\tprint(f'Class mapping has been written to {class_mapping_filename}, and can be loaded when testing to ensure correct results')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape_img = (None, None, 3)\n",
    "\n",
    "img_input = Input(shape=input_shape_img)\n",
    "roi_input = Input(shape=(None, 4))\n",
    "\n",
    "# define the base network\n",
    "shared_layers = nn.nn_base(img_input, trainable=True)\n",
    "\n",
    "# define the RPN, built on the base layers\n",
    "num_anchors = len(model_params['anchor_box_scales']) * len(model_params['anchor_box_ratios'])\n",
    "rpn = nn.rpn(shared_layers, num_anchors)\n",
    "# create model for RPN\n",
    "model_rpn = Model(img_input, rpn[:2])\n",
    "\n",
    "# define the classifier, built on the base layer and rpn\n",
    "classifier = nn.classifier(shared_layers, roi_input, num_rois, nb_classes=len(classes_count))\n",
    "# create model for object classification\n",
    "model_classifier = Model([img_input, roi_input], classifier)\n",
    "\n",
    "# this is a model that holds both the RPN and the classifier, used to load/save weights for the models\n",
    "model_all = Model([img_input, roi_input], rpn[:2] + classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = [s for s in all_imgs if s['imageset'] == 'train']\n",
    "val_imgs = [s for s in all_imgs if s['imageset'] == 'val']\n",
    "\n",
    "random.shuffle(train_imgs)\n",
    "num_imgs = len(train_imgs)\n",
    "\n",
    "print(f'Num train samples {len(train_imgs)}')\n",
    "print(f'Num val samples {len(val_imgs)}')\n",
    "\n",
    "# define generators for ROI\n",
    "data_gen_train = data_generators.get_anchor_gt(train_imgs, classes_count, config, model_params, nn.get_img_output_length, mode='train')\n",
    "data_gen_val = data_generators.get_anchor_gt(val_imgs, classes_count, config, model_params, nn.get_img_output_length, mode='val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because I can only run the session several hours one time (then I need to connect again), \n",
    "# I need to save the model and load the model to continue training\n",
    "if not os.path.isfile(model_path):\n",
    "    # If this is the begin of the training, load the pre-traind base network such as vgg-16\n",
    "    try:\n",
    "        print('This is the first time of your training')\n",
    "        print('loading weights from {}'.format(base_net_weights))\n",
    "        model_rpn.load_weights(base_net_weights, by_name=True)\n",
    "        model_classifier.load_weights(base_net_weights, by_name=True)\n",
    "    except:\n",
    "        print('Could not load pretrained model weights. Weights can be found in the keras application folder \\\n",
    "            https://github.com/fchollet/keras/tree/master/keras/applications')\n",
    "    \n",
    "    # Create the record.csv file to record losses, acc and mAP\n",
    "    record_df = pd.DataFrame(columns=['mean_overlapping_bboxes', 'class_acc', 'loss_rpn_cls', 'loss_rpn_regr', 'loss_class_cls', 'loss_class_regr', 'curr_loss', 'elapsed_time', 'mAP'])\n",
    "else:\n",
    "    # If this is a continued training, load the trained model from before\n",
    "    print('Continue training based on previous trained model')\n",
    "    print('Loading weights from {}'.format(model_path))\n",
    "    model_rpn.load_weights(model_path, by_name=True)\n",
    "    model_classifier.load_weights(model_path, by_name=True)\n",
    "    \n",
    "    # Load the records\n",
    "    record_df = pd.read_csv(record_path)\n",
    "\n",
    "    r_mean_overlapping_bboxes = record_df['mean_overlapping_bboxes']\n",
    "    r_class_acc = record_df['class_acc']\n",
    "    r_loss_rpn_cls = record_df['loss_rpn_cls']\n",
    "    r_loss_rpn_regr = record_df['loss_rpn_regr']\n",
    "    r_loss_class_cls = record_df['loss_class_cls']\n",
    "    r_loss_class_regr = record_df['loss_class_regr']\n",
    "    r_curr_loss = record_df['curr_loss']\n",
    "    r_elapsed_time = record_df['elapsed_time']\n",
    "    r_mAP = record_df['mAP']\n",
    "\n",
    "    print('Already train %dK batches'% (len(record_df)))\n",
    "\n",
    "optimizer = Adam(lr=1e-5)\n",
    "optimizer_classifier = Adam(lr=1e-5)\n",
    "model_rpn.compile(optimizer=optimizer, loss=[model_losses.rpn_loss_cls(num_anchors), model_losses.rpn_loss_regr(num_anchors)])\n",
    "model_classifier.compile(optimizer=optimizer_classifier, loss=[model_losses.class_loss_cls, model_losses.class_loss_regr(len(classes_count)-1)], metrics={f'dense_class_{len(classes_count)}': 'accuracy'})\n",
    "model_all.compile(optimizer='sgd', loss='mae')\n",
    "\n",
    "total_epochs = len(record_df)\n",
    "r_epochs = len(record_df)\n",
    "total_epochs += num_epochs\n",
    "\n",
    "epoch_length = 1000\n",
    "iter_num = 0\n",
    "\n",
    "losses = np.zeros((epoch_length, 5))\n",
    "rpn_accuracy_rpn_monitor = []\n",
    "rpn_accuracy_for_epoch = []\n",
    "\n",
    "if len(record_df)==0:\n",
    "    best_loss = np.Inf\n",
    "else:\n",
    "    best_loss = np.min(r_curr_loss)\n",
    "\n",
    "class_mapping_inv = {v: k for k, v in class_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting training')\n",
    "start_time = time.time()\n",
    "vis = True\n",
    "for epoch_num in range(num_epochs):\n",
    "\n",
    "\tprogbar = generic_utils.Progbar(epoch_length)\n",
    "\tprint('Epoch {}/{}'.format(r_epochs + 1, total_epochs))\n",
    "    \n",
    "\tr_epochs += 1\n",
    "\n",
    "\twhile True:\n",
    "\t\ttry:\n",
    "\t\t\tif len(rpn_accuracy_rpn_monitor) == epoch_length and verbose:\n",
    "\t\t\t\tmean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor))/len(rpn_accuracy_rpn_monitor)\n",
    "\t\t\t\trpn_accuracy_rpn_monitor = []\n",
    "\t\t\t\tprint(f'Average number of overlapping bounding boxes from RPN = {mean_overlapping_bboxes} for {epoch_length} previous iterations')\n",
    "\t\t\t\tif mean_overlapping_bboxes == 0:\n",
    "\t\t\t\t\tprint('RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.')\n",
    "\n",
    "\t\t\tX, Y, img_data = next(data_gen_train)\n",
    "\n",
    "\t\t\tloss_rpn = model_rpn.train_on_batch(X, Y)\n",
    "\t\t\tP_rpn = model_rpn.predict_on_batch(X)\n",
    "\n",
    "\t\t\tR = roi_helpers.rpn_to_roi(P_rpn[0], P_rpn[1], model_params, use_regr=True, max_boxes=300, overlap_thresh=0.7)\n",
    "\t\t\t# note: calc_iou converts from (x1,y1,x2,y2) to (x,y,w,h) format\n",
    "            # X2: bboxes that iou > C.classifier_min_overlap for all gt bboxes in 300 non_max_suppression bboxes\n",
    "            # Y1: one hot code for bboxes from above => x_roi (X)\n",
    "            # Y2: corresponding labels and corresponding gt bboxes\n",
    "\t\t\tX2, Y1, Y2, IouS = roi_helpers.calc_iou(R, img_data, model_params, class_mapping)\n",
    "\n",
    "\t\t\tif X2 is None:\n",
    "\t\t\t\trpn_accuracy_rpn_monitor.append(0)\n",
    "\t\t\t\trpn_accuracy_for_epoch.append(0)\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tneg_samples = np.where(Y1[0, :, -1] == 1)\n",
    "\t\t\tpos_samples = np.where(Y1[0, :, -1] == 0)\n",
    "\n",
    "\t\t\tif len(neg_samples) > 0:\n",
    "\t\t\t\tneg_samples = neg_samples[0]\n",
    "\t\t\telse:\n",
    "\t\t\t\tneg_samples = []\n",
    "\n",
    "\t\t\tif len(pos_samples) > 0:\n",
    "\t\t\t\tpos_samples = pos_samples[0]\n",
    "\t\t\telse:\n",
    "\t\t\t\tpos_samples = []\n",
    "\t\t\t\n",
    "\t\t\trpn_accuracy_rpn_monitor.append(len(pos_samples))\n",
    "\t\t\trpn_accuracy_for_epoch.append((len(pos_samples)))\n",
    "\n",
    "\t\t\tif num_rois > 1:\n",
    "\t\t\t\tif len(pos_samples) < num_rois//2:\n",
    "\t\t\t\t\tselected_pos_samples = pos_samples.tolist()\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tselected_pos_samples = np.random.choice(pos_samples, num_rois//2, replace=False).tolist()\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tselected_neg_samples = np.random.choice(neg_samples, num_rois - len(selected_pos_samples), replace=False).tolist()\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tselected_neg_samples = np.random.choice(neg_samples, num_rois - len(selected_pos_samples), replace=True).tolist()\n",
    "\n",
    "\t\t\t\tsel_samples = selected_pos_samples + selected_neg_samples\n",
    "\t\t\telse:\n",
    "\t\t\t\t# in the extreme case where num_rois = 1, we pick a random pos or neg sample\n",
    "\t\t\t\tselected_pos_samples = pos_samples.tolist()\n",
    "\t\t\t\tselected_neg_samples = neg_samples.tolist()\n",
    "\t\t\t\tif np.random.randint(0, 2):\n",
    "\t\t\t\t\tsel_samples = random.choice(neg_samples)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tsel_samples = random.choice(pos_samples)\n",
    "\n",
    "\t\t\t# training_data: [X, X2[:, sel_samples, :]]\n",
    "            # labels: [Y1[:, sel_samples, :], Y2[:, sel_samples, :]]\n",
    "            #  X                     => img_data resized image\n",
    "            #  X2[:, sel_samples, :] => num_rois (4 in here) bboxes which contains selected neg and pos\n",
    "            #  Y1[:, sel_samples, :] => one hot encode for num_rois bboxes which contains selected neg and pos\n",
    "            #  Y2[:, sel_samples, :] => labels and gt bboxes for num_rois bboxes which contains selected neg and pos\n",
    "\t\t\tloss_class = model_classifier.train_on_batch([X, X2[:, sel_samples, :]], [Y1[:, sel_samples, :], Y2[:, sel_samples, :]])\n",
    "\n",
    "\t\t\tlosses[iter_num, 0] = loss_rpn[1]\n",
    "\t\t\tlosses[iter_num, 1] = loss_rpn[2]\n",
    "\n",
    "\t\t\tlosses[iter_num, 2] = loss_class[1]\n",
    "\t\t\tlosses[iter_num, 3] = loss_class[2]\n",
    "\t\t\tlosses[iter_num, 4] = loss_class[3]\n",
    "\n",
    "\t\t\tprogbar.update(iter_num+1, [('rpn_cls', losses[iter_num, 0]), ('rpn_regr', losses[iter_num, 1]),\n",
    "\t\t\t\t\t\t\t\t\t  ('detector_cls', losses[iter_num, 2]), ('detector_regr', losses[iter_num, 3])])\n",
    "\n",
    "\t\t\titer_num += 1\n",
    "\t\t\t\n",
    "\t\t\tif iter_num == epoch_length:\n",
    "\t\t\t\tloss_rpn_cls = np.mean(losses[:, 0])\n",
    "\t\t\t\tloss_rpn_regr = np.mean(losses[:, 1])\n",
    "\t\t\t\tloss_class_cls = np.mean(losses[:, 2])\n",
    "\t\t\t\tloss_class_regr = np.mean(losses[:, 3])\n",
    "\t\t\t\tclass_acc = np.mean(losses[:, 4])\n",
    "\n",
    "\t\t\t\tmean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n",
    "\t\t\t\trpn_accuracy_for_epoch = []\n",
    "\n",
    "\t\t\t\tif verbose:\n",
    "\t\t\t\t\tprint(f'Mean number of bounding boxes from RPN overlapping ground truth boxes: {mean_overlapping_bboxes}')\n",
    "\t\t\t\t\tprint(f'Classifier accuracy for bounding boxes from RPN: {class_acc}')\n",
    "\t\t\t\t\tprint(f'Loss RPN classifier: {loss_rpn_cls}')\n",
    "\t\t\t\t\tprint(f'Loss RPN regression: {loss_rpn_regr}')\n",
    "\t\t\t\t\tprint(f'Loss Detector classifier: {loss_class_cls}')\n",
    "\t\t\t\t\tprint(f'Loss Detector regression: {loss_class_regr}')\n",
    "\t\t\t\t\tprint(f'Elapsed time: {time.time() - start_time}')\n",
    "\t\t\t\t\telapsed_time = (time.time()-start_time)/60\n",
    "\n",
    "\t\t\t\tcurr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
    "\t\t\t\titer_num = 0\n",
    "\t\t\t\tstart_time = time.time()\n",
    "\n",
    "\t\t\t\tif curr_loss < best_loss:\n",
    "\t\t\t\t\tif verbose:\n",
    "\t\t\t\t\t\tprint(f'Total loss decreased from {best_loss} to {curr_loss}, saving weights')\n",
    "\t\t\t\t\tbest_loss = curr_loss\n",
    "\t\t\t\t\tmodel_all.save_weights(model_path_regex.group(1) + model_path_regex.group(2))\n",
    "\n",
    "\t\t\t\tnew_row = {'mean_overlapping_bboxes':round(mean_overlapping_bboxes, 3), \n",
    "                           'class_acc':round(class_acc, 3), \n",
    "                           'loss_rpn_cls':round(loss_rpn_cls, 3), \n",
    "                           'loss_rpn_regr':round(loss_rpn_regr, 3), \n",
    "                           'loss_class_cls':round(loss_class_cls, 3), \n",
    "                           'loss_class_regr':round(loss_class_regr, 3), \n",
    "                           'curr_loss':round(curr_loss, 3), \n",
    "                           'elapsed_time':round(elapsed_time, 3), \n",
    "                           'mAP': 0}\n",
    "\n",
    "\t\t\t\trecord_df = record_df.append(new_row, ignore_index=True)\n",
    "\t\t\t\trecord_df.to_csv(record_path, index=0)\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f'Exception: {e}')\n",
    "\t\t\tcontinue\n",
    "\n",
    "print('Training complete, exiting.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(np.arange(0, r_epochs), record_df['mean_overlapping_bboxes'], 'r')\n",
    "plt.title('mean_overlapping_bboxes')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(np.arange(0, r_epochs), record_df['class_acc'], 'r')\n",
    "plt.title('class_acc')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_cls'], 'r')\n",
    "plt.title('loss_rpn_cls')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_regr'], 'r')\n",
    "plt.title('loss_rpn_regr')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(np.arange(0, r_epochs), record_df['loss_class_cls'], 'r')\n",
    "plt.title('loss_class_cls')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(np.arange(0, r_epochs), record_df['loss_class_regr'], 'r')\n",
    "plt.title('loss_class_regr')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(0, r_epochs), record_df['curr_loss'], 'r')\n",
    "plt.title('total_loss')\n",
    "plt.show()\n",
    "\n",
    "# plt.figure(figsize=(15,5))\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.plot(np.arange(0, r_epochs), record_df['curr_loss'], 'r')\n",
    "# plt.title('total_loss')\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.plot(np.arange(0, r_epochs), record_df['elapsed_time'], 'r')\n",
    "# plt.title('elapsed_time')\n",
    "# plt.show()\n",
    "\n",
    "# plt.title('loss')\n",
    "# plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_cls'], 'b')\n",
    "# plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_regr'], 'g')\n",
    "# plt.plot(np.arange(0, r_epochs), record_df['loss_class_cls'], 'r')\n",
    "# plt.plot(np.arange(0, r_epochs), record_df['loss_class_regr'], 'c')\n",
    "# # plt.plot(np.arange(0, r_epochs), record_df['curr_loss'], 'm')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('object_detection')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "523c085937921c9bf1754be3fc06c3736dd9e909273ccc15755aad185ca77468"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
